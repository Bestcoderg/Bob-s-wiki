# 内存 物理结构/IO

## 内存介绍

![Untitled](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled.png)

### 内存物理结构抽象

一个内存是由若干个黑色的内存颗粒构成的。每一个内存颗粒叫做一个chip。每个chip内部，是由8个bank组成的。其构造如下图：

![Untitled](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled%201.png)

而每一个bank是一个二维平面上的矩阵，前面文章中我们说到过。矩阵中每一个元素中都是保存了1个字节，也就是8个bit。

![Untitled](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled%202.png)

**内存编址方式**

那么对于我们在应用程序中内存中地址连续的8个字节,例如0x0000-0x0007，是从位于bank上的呢？直观感觉，应该是在第一个bank上吗？ 其实不是的，程序员视角看起来连续的地址0x0000-0x0007，实际上位8个bank中的，每一个bank只保存了一个字节。在物理上，他们并不连续。下图很好地阐述了实际情况。

![Untitled](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled%203.png)

你可能想知道这是为什么，原因是电路工作效率。内存中的8个bank是可以并行工作的。 如果你想读取址0x0000-0x0007，每个bank工作一次，拼起来就是你要的数据，IO效率会比较高。但要存在一个bank里，那这个bank只能自己干活。只能串行进行读取，需要读8次，这样速度会慢很多。

**所以，内存对齐最最底层的原因是内存的IO是以8个字节64bit为单位进行的。** 对于64位数据宽度的内存，假如cpu也是64位的cpu（现在的计算机基本都是这样的），每次内存IO获取数据都是从同行同列的8个bank中各自读取一个字节拼起来的。从内存的0地址开始，0-7字节的数据可以一次IO读取出来，8-15字节的数据也可以一次读取出来。

换个例子，假如你指定要获取的是0x0001-0x0008，也是8字节，但是不是0开头的，内存需要怎么工作呢？没有好办法，内存只好先工作一次把0x0000-0x0007取出来，然后再把0x0008-0x0015取出来，把两次的结果都返回给你。 CPU和内存IO的硬件限制导致没办法一次跨在两个数据宽度中间进行IO。这样你的应用程序就会变慢，算是计算机因为你不懂内存对齐而给你的一点点惩罚。

## 内存物理实现

### 内存频率与数据宽度

从2001年DDR内存面世以来发展到今天，已经走过了DDR、DDR2、DDR3、DDR4四个大的规格时代了（DDR5现在也出来了）。内存的工作频率也从DDR时代的266MHz进化到了今天的3200MHz。这个频率在操作系统里叫Speed、在内存术语里叫等效频率、或干脆直接简称频率。这个频率越高，每秒钟内存IO的吞吐量越大。但其实内存有一个最最基本的频率叫核心频率，是实际内存电路的工作时的一个振荡频率。它是内存工作的基础，很大程度上会影响内存的IO延迟。

在Linux上可以查看内存的信息：`dmidecode | grep -P -A16 "Memory Device"`

对于我们开发者来说，其中有两个数据比较关键。

- Speed： 每秒能进行内存数据传输的速度，
- Data Width： 内存工作一次传输的数据宽度

把Data Width和Speed相乘后得到的就是数据带宽了，我们把历史上各个阶段的内存的Speed和带宽汇总了一下，如下图。如 3200MHz*64bit = 25.6GB/s

![Untitled](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled%204.png)

### 核心频率

通过Linux我们只看到了内存的一个Speed，它是数据传输的频率。这个频率又叫Data Speed，或等效频率。各个商家在内存的销售页面上也把这个频率标在特别明显的位置，提醒消费者他家的内存有多快多快。但其实从内存条的技术参数上来讲，有个最为重要的频率，是**核心频率，它是内存电路的震荡频率，是内存一切工作的基石**。

我们来看一下各代内存的更全面详细的数据。

![Untitled](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled%205.png)

先介绍三个频率：

**核心频率：**即内部存储颗粒工作的频率，现在很难提升，提升的花费也很大。n-prefetch 需要内部存储单元在核心频率下多读 n 倍的数据（通过多条线来实现）。

**时钟频率：**指的是 I/O 缓存区的时钟频率，根据 n-bites 的 prefetch，时钟频率是核心频率的 n/2 倍(因为第一次预读的翻倍是通过利用上下沿触发实现的)。

**等效频率：**即外部接口需要的频率，由于采用**上下沿双触发**，所以是时钟频率的两倍。

我汇总了从SDR时代，一直到目前主流的DDR4的内存的频率表对比。大家可以看到**核心频率已经多年没有实质性进步了，这是受物理材料的极限限制，内存的核心频率一直在133MHz~200MHz之间徘徊**。我们所看到的内存Speed是在这个核心频率的基础上，通过各种技术手段放大出来的。之所以我们感觉内存在越来越快，就是放大技术手段在不断进步而已。

### 从SDR到DDR4

- **SDR时代**：在最古老的SDR（Single Data Rate SDRAM）年代里，一个时钟脉冲只能在脉冲上沿时传输数据，所以也叫单倍数据传输率内存。这个时期内存的提升方法就是提升内存电路的核心频率。
- **DDR时代**：但是内存制造商们发现核心频率到了200MHz再提升的话，难度就很大了。所以在电路时钟周期内预取(prefetch) 2bit，**输出的时候就在上升期和下降期各传输一次数据**。所以核心频率不变的情况下，Speed（等效频率）就翻倍了。
- **DDR2时代**：同样是在上下沿各传一次数据，但将Prefech提升为4，每个电路周期一次读取4bit。所以DDR2的Speed（等效频率）就达到了核心频率的4倍。
- **DDR3时代**：同样也是上下沿各传一次数据，进一步将Prefect提升为8。所以DDR3的等效频率可以达到核心频率的8倍。
- **DDR4时代**：这时预取的提升已经非常困难，所以和DDR3一样，Prefech仍然为8。内存制造商们又另辟蹊径，提出了Bank Group设计。允许各个Bank Group具备独立启动操作读、写等动作特性。所以等效频率可以提升到核心频率的16倍。

首先，简单介绍一下Prefetch技术。所谓prefetch，就是预加载，这是DDR时代提出的技术。在SDR中，并没有这一技术，所以其每一个存储单元的存储容量芯片数据IO位宽。

- **什么是存储单元呢？**

SDRAM的内部是一个存储阵列，称为Bank。要想准确地找到所需的存储单元就先指定一个（row）,再指定一个列（Column）,这就是内存芯片寻址的基本原理。

![Untitled](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled%206.png)

所谓**芯片位宽**就是SDRAM内存芯片(Clip)一次传输率的数据量。那么这个存储单元的容量就是芯片的位宽（也是L-Bank的位宽）。

**存储单元数量**=**行数*列数**(得到一个L-Bank的存储单元数量)* **L-Bank的数量**

**芯片的容量**=**存储单元的总数*芯片的位宽**

DDR SDRAM内部存储单元容量是芯片位宽（芯片I/O口位宽）的一倍；

DDR2 SDRAM内部存储单元容量是芯片位宽的四倍；

DDR3 SDRAM内部存储单元容量是芯片位宽的八倍；

DDR4 SDRAM内部存储单元容量是芯片位宽的八倍。

进入DDR时代之后，就有了prefetch技术，DDR是**两位预取（2-bit Prefetch）**，有的公司则贴切的称之为2-n Prefetch（n代表芯片位宽，chip 对外的 I/O width）。DDR2是**四位预取（4-bit Prefetch）**，DDR3和DDR4都是八**位预取（8-bit Prefetch）。**而8-bit Prefetch可以使得内核时钟是DDR时钟的四分之一，这也是Prefetch的根本意义所在。

**补充说明：芯片位宽的另一种说法是配置模式（Configuration），在DDR3时代，一般有x4，x8，x16。**下面以DDR3为例，下图是个简单 一个简单Read预取示意图，Write可以看做是 个逆向过程。

![figure 1 ](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled%207.png)

figure 1 

当DDR3 为x8 Configuration时，一个Cell的容量为8x8bits，即8个字节。换一句话说，在指定bank、row地址和col地址之后，可以往该地址内写入（或读取）8 Bytes。

整个内存的逻辑可以kan'xia

![figure 2](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled%208.png)

figure 2

大图可能看不清楚，我们可以研究一下其中的细节：

下图的部分便是figure1在实际电路中的实现。可以清晰的看到，一个chip(内存芯片)由8片L-Bank组成，一个cell的容量为 64bits = 8*8bits，一个内存单元的容量为8bits

![Untitled](%E5%86%85%E5%AD%98%20%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%20IO%200531df62dade4010a7804d41820dccce/Untitled%209.png)

## 内存IO延迟

除了频率以外，内存还有几个比较重要的参数，但是同样在Linux里没有找到查看的命令。内存的销售页面想找到这几个参数也不是特别容易。

所有的内存条都有CL-tRCD-tRP-tRAS四个参数。其中最重要的是CL-tRCD-tRP这三个参数，只要你费点劲，所有的在售内存你都能找到这3个值。例如经典的DDR3-1066、DDR3-1333及DDR3-1600的CL值分别为7-7-7、8-8-8及9-9-9。现在京东上一条比较流行的台式机内存金士顿(Kingston)DDR4 2400 8G，其时序是17-17-17。

第四个参数有时候会被省略。原因有二，第一：现在的开发者不需要直接和内存打交道，而操作系统呢又做的比较内存友好，很少会有这个开销真正发生。第二，这个开销的值要比其它的值大很多，实在不太好看。商家为了内存能多卖一些，干脆就避而不谈了。

我们今天来详细理解一下这四个参数的含义：

- CL(Column Address Latency）：发送一个列地址到内存与数据开始响应之间的周期数
- tRCD（Row Address to Column Address Delay）：打开一行内存并访问其中的列所需的最小时钟周期数
- tRP(Row Precharge Time)：发出预充电命令与打开下一行之间所需的最小时钟周期数。
- tRAS(Row Active Time)：行活动命令与发出预充电命令之间所需的最小时钟周期数。也就是对下一次预充电时间进行限制。

要注意除了CL是固定周期数以外，其它的三个都是最小周期。另外上面的参数都是以**时钟周期**为单位的。时钟周期的计算也是简单的，因为现代的内存都是一个时钟周期上下沿分别各传输一次数据，所以用Speed/2就可以得出，例如笔者的机器的Speed是1066MHz，则时钟周期为533MHz。自己的机器可以通过dmidecode命令查看：`dmidecode | grep -P -A16 "Memory Device"`

### IO延迟计算

内存也存在和磁盘一样，随机IO比顺序IO要慢的问题。如果行地址同上一次访问的不一致，则需要重新拷贝row buffer，延迟周期需要tRP+tRCD+CL。而如果是顺序IO的话（行地址不变），只需要CL个周期既可完成。

我们接着估算下内存的延时,笔者的机器上的内存参数Speed为1066MHz（通过dmidecode查得），该值除以2就是时钟周期的频率=1066/2=533Mhz。其延迟周期为7-7-7-24。

- 随机IO：这种状况下需要tRP+tRCD+CL个时钟周期，7+7+7=21个周期。但是还有个tRAS的限制，两次行地址预充电不得小于24。所以我们得按24来计算，24*(1s/533Mhz) = 45ns
- 顺序IO：这种状况下只需要CL个时钟周期 7*(1s/533Mhz)=13ns

### **CPU的Cache Line**

因为对于内存来说，随机IO一次开销比顺序IO高好几倍。所以操作系统在工作的时候，会尽量让内存通过顺序IO的方式来进行。做法关键就是**Cache Line**。当CPU发现缓存不命中的时候，实际上从来不会向内存去请求1个字节，8个字节这种。而是一次性就要64字节，然后放到自己的Cache中存起来。

用上面的例子来看，

- 如果随机请求8字节：耗时是45ns
- 如果随机请求64字节：耗时是45+7*13 = 136ns

开销也没贵多少，因为只有第一个字节可能是随机IO，后面的7个字节都是顺序IO。数据是8倍，但是IO耗时只有3倍，而且取出来的数据后面大概率要用，所以计算机内部就这么搞了，通过这种方式帮你避免一些随机IO！

另外，内存也支持burst(突发传输)模式，在这种模式下可以只传入一次行列地址，就命令内存返回该内存开头的连续字节数据，比如64字节。这种模式下，只有第一次的8字节需要真正的行列访问延迟，后面的7个字节可以直接按内存的数据频率给吐出来。

### **为什么内存越进步，延迟周期反而会变大了呢？**

这就是因为标示延迟周期数是用延迟时间除以内存时钟周期(Speed/2)得出来的。这其实不算太科学，最直接的办法应该是用延迟时间来评估。

**延迟时间很大程度上是受内存的核心频率的制约的**。而这些年核心频率又基本上没有进步，所以延迟时间也不会有实质的降低。假定延迟时间不变，而时钟周期翻倍了，这样延迟周期看起来就是新的内存更大。