# 页缓存&内存组织方式

## 什么是页缓存?

**在最开头，我一定要说，页缓存不是页表！页缓存不是页表！页缓存不是页表！**页缓存是针对于某个文件所做的一种缓存机制。

在面对文件时，有两个很重要的问题需要操作系统去解决。第一个是相对内存而言，慢的让人发狂的硬盘驱动器，尤其是磁盘寻道。第二个是需要将文件内容一次性地加载到物理内存中，以便程序间共享文件内容。如果你在 Windows 中使用进程浏览器去查看它的进程，你将会看到每个进程中加载了大约 ~15MB 的公共 DLL。我的 Windows 机器上现在大约运行着 100 个进程，因此，**如果不共享的话**，仅这些公共的 DLL 就要使用高达 ~1.5 GB 的物理内存。如果是那样的话，那就太糟糕了。同样的，几乎所有的 Linux 进程都需要 ld.so 和 libc，加上其它的公共库，它们占用的内存数量也不是一个小数目。**linux 中页缓存的本质就是对于磁盘中的部分数据在内存中保留一定的副本，使得应用程序能够快速的读取到磁盘中相应的数据，并实现不同进程之间的数据共享。**

幸运的是，这两个问题都用一个办法解决了：**页面缓存** —— **保存在内存中的页面大小的文件块**。（页面大小是以4KB为一个基本单元）为了用图去说明页面缓存，我捏造出一个名为 `render` 的 Linux 程序，它打开了文件 `scene.dat`，并且一次读取 512 字节，并将文件内容存储到一个分配到堆中的块上。第一次读取的过程如下：

![%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled.png](%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled.png)

1. `render` 请求 `scene.dat` 从位移 0 开始的 512 字节。
2. 内核搜寻页面缓存中 `scene.dat` 的 4kb 块，以满足该请求。假设该数据没有缓存。
3. 内核分配页面帧，初始化 I/O 请求，将 `scend.dat` 从位移 0 开始的 4kb 复制到分配的页面帧。
4. 内核从页面缓存复制请求的 512 字节到用户缓冲区，系统调用 `read()` 结束。

读取完 **12KB** 的文件内容以后，`render` 程序的堆和相关的页面帧如下图所示：

![%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled%201.png](%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled%201.png)

它看起来很简单，其实这一过程做了很多的事情。首先，虽然这个程序使用了普通的读取（read）调用，但是，已经有三个 4KB 的页面帧将文件 scene.dat 的一部分内容保存在了页面缓存中。虽然有时让人觉得很惊奇，但是，普通的文件 I/O 就是这样通过页面缓存来进行的。在 x86 架构的 Linux 中，**内核将文件认为是一系列的 4KB 大小的块（页）**。如果你从文件中读取单个字节，包含这个字节的整个 4KB 块将被从磁盘中读入到页面缓存中。这是可以理解的，因为磁盘通常是持续吞吐的，并且程序一般也不会从磁盘区域仅仅读取几个字节。页面缓存知道文件中的每个 4KB 块的位置，在上图中用 #0、#1 等等来描述。Windows 使用 256KB 大小的 视图(view)，类似于 Linux 的页面缓存中的 页面(page)。

不幸的是，在一个普通的文件读取中，内核必须拷贝页面缓存中的内容到用户缓冲区中，它不仅花费 CPU 时间和影响 CPU 缓存，在复制数据时也浪费物理内存。如前面的图示，scene.dat 的内存被存储了两次，并且，程序中的每个实例都用另外的时间去存储内容。我们虽然解决了从磁盘中读取文件缓慢的问题，但是在其它的方面带来了更痛苦的问题。**内存映射文件是解决这种痛苦的一个方法，详情请看：**[内存映射 mmap/system V](%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84%20mmap%20system%20V%20525b256cfb2e457c86c5ac99d291aff7.md) 

![%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled%202.png](%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled%202.png)

通过使用内存映射的方式，我们将虚拟内存区域与磁盘空间直接建立映射关系，并且采用延迟加载的方式，**直到调用到对应的虚拟内存时才引起缺页中断**（此时才将虚拟内存对应的磁盘页加载到物理内存中）通过这种内存映射的方式，至少带来了两个好处：**一是磁盘页不需要先加载入页缓存再拷贝到用户进程对应的物理内存中（这样拷贝了两次），二是页缓存不再被这类数据大量的占用了，减少了页缓存中页面的替换。**这样可以显著提升性能：Windows 系统编程 报告指出，在相关的普通文件读取上运行时性能提升多达 30% 。请记住，**磁盘读取的速度要慢于内存 5 个数量级，因此，命中一个页面缓存是一件有非常大收益的事情。因此，只要有足够大的物理内存，缓存就应该保持全满**。

由于页面缓存架构的原因，当程序调用 write() 时，字节只是被简单地拷贝到页面缓存中，并将这个页面标记为“脏”页面。磁盘 I/O 通常并不会立即发生，因此，你的程序并不会被阻塞在等待磁盘写入上。副作用是，如果这时候发生了电脑死机，你的写入将不会完成，因此，对于至关重要的文件，像数据库事务日志，要求必须进行 fsync()（仍然还需要去担心磁盘控制器的缓存失败问题），另一方面，读取将被你的程序阻塞，直到数据可用为止**。内核采取预加载的方式来缓解这个矛盾，它一般提前预读取几个页面并将它加载到页面缓存中，以备你后来的读取**。在你计划进行一个顺序或者随机读取时，你可以通过 提示(hint)帮助内核去调整这个预加载行为。Linux 会对内存映射的文件进行 预读取，但是我不确定 Windows 的行为。

### 当加载了一个动态库，这是内存内部发生的变化

一个文件映射可以是私有的，也可以是共享的(可以看到：[内存映射 mmap/system V](%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84%20mmap%20system%20V%20525b256cfb2e457c86c5ac99d291aff7.md) ，其中的四种映射类型)。当然，这只是针对内存中内容的更新而言：**在一个私有的内存映射上，更新并不会提交到磁盘或者被其它进程可见**，然而，共享的内存映射，则正好相反，它的任何更新都会提交到磁盘上，并且对其它的进程可见。内核使用 **写时复制(copy on write)（CoW）机制**，这是通过 页面表条目(page table entry)（PTE）来实现这种私有的映射。在下面的例子中，render 和另一个被称为 render3d 的程序都私有映射到 scene.dat 上。然后 render 去写入映射的文件的虚拟内存区域：

![%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled%203.png](%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled%203.png)

1. 两个程序私有地映射 `scene.dat`，内核误导它们并将它们映射到页面缓存，但是使该页面表条目只读。
2. `render` 试图写入到映射 `scene.dat` 的虚拟页面，处理器发生页面故障。
3. **内核分配页面帧，复制 `scene.dat` 的第二块内容到其中，并映射故障的页面到新的页面帧。**
4. 继续执行。程序就当做什么都没发生。

上面展示的只读页面表条目并不意味着映射是只读的，它只是内核的一个用于共享物理内存的技巧，直到尽可能的最后一刻之前。你可以认为“私有”一词用的有点不太恰当，你只需要记住，这个“私有”仅用于更新的情况。这种设计的重要性在于，要想看到被映射的文件的变化，其它程序只能读取它的虚拟页面。一旦“写时复制”发生，从其它地方是看不到这种变化的。但是，内核并不能保证这种行为，因为它是在 x86 中实现的，从 API 的角度来看，这是有意义的。相比之下，**一个共享的映射只是将它简单地映射到页面缓存上。更新会被所有的进程看到并被写入到磁盘上**。最终，如果上面的映射是只读的，页面故障将触发一个内存段失败而不是写到一个副本

**动态加载库(采用私有文件映射加载)**是通过文件映射融入到你的程序的地址空间中的。这没有什么可奇怪的，它通过普通的 API 为你提供与私有文件映射相同的效果。下面的示例展示了映射文件的 render 程序的两个实例运行的地址空间的一部分，以及物理内存，尝试将我们看到的许多概念综合到一起。

![%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled%204.png](%E9%A1%B5%E7%BC%93%E5%AD%98&%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E6%96%B9%E5%BC%8F%20351ab7a6eb64447a9ed2b9178098c8ae/Untitled%204.png)

## 页缓存的实现

既然页缓存是以页为单位进行数据管理的，那么必须**在内核中标识该物理页**。**其实每个真正存放数据的物理页帧都对应一个管理结构体，称之为 struct page**，其结构体如下。**（pcb&mm_struct&vma可以看[Linux 进程控制块PCB](Linux%20%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97PCB%202d908aa06c3b4b59bfe309147b0004b4.md) ）**

```cpp
struct page  {
    unsigned long   flags;
    atomic_t    _count;
    atomic_t    _mapcount;
    unsigned long    private;
    **struct address_space    *mapping;**
    pgoff_t    index;
    struct list_head    lru;
    void*    virtual;
};
```

- **详解 struct page 参数：**
  
    **flags:**  描述 page 当前的状态和其他信息，如当前的 page 是否是脏页 PG_dirty；是否是最新的已经同步到后备存储的页 PG_uptodate; 是否处于 lru 链表上等；
    
    **_count：**引用计数，标识内核中引用该 page 的次数，如果要操作该 page，引用计数会 + 1，操作完成之后 -1。当该值为 0 时，表示没有引用该 page 的位置，所以该 page 可以被解除映射，这在内存回收的时候是有用的；
    
    **_mapcount:**  页表被映射的次数，也就是说 page 同时被多少个进程所共享，初始值为 - 1，如果只被一个进程的页表映射了，该值为 0。
    
    _mapping 有三种含义：
    
    a. 如果 mapping  =  0，说明该 page 属于交换缓存（swap cache); 当需要地址空间时会指定交换分区的地址空间 swapper_space;
    
    b. 如果 mapping !=  0,  bit[0]  =  0,  说明该 page 属于页缓存或者文件映射，mapping 指向文件的地址空间 address_space；
    
    c. 如果 mapping !=  0,  bit[0]  !=0 说明该 page 为匿名映射，mapping 指向 struct  anon_vma 对象；
    
    （注意区分_count 和_mapcount，_mapcount 表示的是被映射的次数，而_count 表示的是被使用的次数；被映射了不一定被使用，但是被使用之前肯定要先被映射）。
    
    **index:** 在映射的虚拟空间（vma_area) 内的偏移；一个文件可能只是映射了一部分，假设映射了 1M 的空间，那么 index 指的是 1M 空间内的偏移，而不是在整个文件内的偏移；
    
    **private :**  私有数据指针；
    
    **lru:** 当 page 被用户态使用或者是当做页缓存使用的时候，将该 page 连入 zone 中的 lru 链表，供内存回收使用
    

**页缓存就是将一个文件在内存中的所有物理页所组成的一种树形结构**，我们称之为**基数树(radix-tree)**，用于管理属于同一个文件在内存中的缓存内容。[基数树](%E5%9F%BA%E6%95%B0%E6%A0%91%20a0f1ef24ed374d5194803512b15569de.md) 

如上所述，一个文件在内存中对应的所有物理页组成了一棵基数树。**而一个文件在内存中具有唯一的 inode 结构标识，inode 结构中有该文件所属的设备及其标识符**，因而，根据一个 inode 能够确定其对应的后备设备。

为了将文件在物理内存中的页缓存和文件及其后备设备关联起来，linux 内核引入了 **address_space 结构体(address_space 与 inode 是一一对应的关系)**。可以说 address_space 结构体是将内存页/页缓存和文件系统关联起来的桥梁，其组成如下：

```cpp
struct address_space {
    struct inode*    host;/*指向与该address_space相关联的inode节点*/
    **struct radix_tree_root    page_tree;/*所有页形成的基数树根节点*/**
    spinlock_t    tree_lock;/*保护page_tree的自旋锁*/
    unsigned int    i_map_writable;/*VM_SHARED的计数*/
    **struct prio_tree_root    i_map;**         
    struct list_head    i_map_nonlinear;
    spinlock_t    i_map_lock;/*保护i_map的自旋锁*/
    atomic_t    truncate_count;/*截断计数*/
    unsigned long    nrpages;/*页总数*/
    pgoff_t    writeback_index;/*回写的起始位置*/
    struct address_space_operation*    a_ops;/*操作表*/
    unsigned long    flags;/*gfp_mask掩码与错误标识*/
    struct backing_dev_info*    backing_dev_info;/*预读信息*/
    spinlock_t    private_lock;/*私有address_space锁*/
    struct list_head    private_list;/*私有address_space链表*/
    struct address_space*    assoc_mapping;/*相关的缓冲*/
}
```

- **详解 address space 参数：**
  
    **host:**  指向与该 address_space 相关联的 inode 节点，inode 节点与 address_space 之间是一一对应关系；
    
    **radix_tree_root:** 指向的 host 文件在该内存中映射的**所有物理页**形成的基数树的根节点，通过根节点就相当于找到了这棵基数树。
    
    **prio_tree_root:** 与**该地址空间相关联的所有进程的虚拟地址区间 vm_area_struct 所对应的整个进程地址空间 mm_struct 形成的优先查找树的根节点**; vm_area_struct 中如果有后备存储，则存在 prio_tree_node 结构体，通过该 prio_tree_node 和 prio_tree_root 结构体，构成了所有与该 address_space 相关联的进程的一棵优先查找树，便于查找所有与该 address_space 相关联的进程；
    
    下面列出 struct prio_tree_root 和 struct prio_tree_node 的结构体。
    
    ```cpp
    struct  prio_tree_root {
        struct prio_tree_node*  prio_tree_root;
        unsigned short              index_bits;
    };
    ```
    
    ```cpp
    struct prio_tree_node {
        struct prio_tree_node*  left;
        struct prio_tree_node*  right; 
        struct prio_tree_node*  parent;
        unsigned long                start;
        unsigned long                last;
    };
    ```
    

**优先搜索树PST请看 ： [优先搜索树 PST](%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E6%A0%91%20PST%2091c1d4655c3c454896e4647f8267ea97.md)** 

为了理清页缓存、文件和进程之间的关系，请看下图：

![Linux%20%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97PCB%202d908aa06c3b4b59bfe309147b0004b4/Untitled%203.png](Linux%20%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97PCB%202d908aa06c3b4b59bfe309147b0004b4/Untitled%203.png)

从以上可以解释可以看出，address_space 成为构建页缓存和文件、页缓存和共享该文件的所有进程之间的桥梁。

**（pcb&mm_struct&vma可以看[Linux 进程控制块PCB](Linux%20%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97PCB%202d908aa06c3b4b59bfe309147b0004b4.md) ）**

**每个进程的地址空间使用 mm_struct 结构体标识，该结构体中包含一系列的由 vm_area_struct 结构体组成的连续地址空间链表。每个 vm_area_struct 中存在 struct file* vm_file 用于指向该连续地址空间中所打开的文件，而 vm_file 通过 struct file 中的 struct path 与 struct dentry 相关联。 struct dentry 中通过 inode 指针指向 inode，inode 与 address_space 一一对应，至此形成了页缓存与文件系统之间的关联；为了便于查找与某个文件相关联的所有进程，address_space 中的 prio_tree_root 指向了所有与该页缓存相关联的进程所形成的优先查找树的根节点。**

![Linux%20%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97PCB%202d908aa06c3b4b59bfe309147b0004b4/Untitled%204.png](Linux%20%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97PCB%202d908aa06c3b4b59bfe309147b0004b4/Untitled%204.png)

这里需要说明的 linux 中文件系统的一点是，内核为每个进程在其地址空间中都维护了**结构体 struct* fd_array[] 用于维护该进程地址空间中打开的文件的指针**；同时内核为所有被打开的文件还维护了系统级的一个**文件描述符表**用以记录该系统打开的所有文件，**供所有进程之间共享；每个被打开的文件都由一个对应的 inode 结构体表示，由系统级的文件描述符表指向。**所以，进程通过自己地址空间中的打开文件描述符表可以找到系统级的文件描述符表，进而找到文件