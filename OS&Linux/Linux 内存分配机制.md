# Linux 内存分配机制

在我们了解了内存的一些基础知识后，我们再来深入了解一下内存的分配机制把**。[虚拟内存(内核空间&用户空间)](%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98(%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4&%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4)%20919e35135f674d998286e9d031aa158a.md)** 

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled.png)

## NUMA

所谓物理内存，就是安装在机器上的，实打实的内存设备（不包括硬件cache），被CPU通过总线访问。在多核系统中，如果物理内存对所有CPU来说没有区别，每个CPU访问内存的方式也一样，则这种体系结构被称为Uniform Memory Access(UMA)。

如果物理内存是分布式的，由多个cell组成（比如每个核有自己的本地内存），那么CPU在访问靠近它的本地内存的时候就比较快，访问其他CPU的内存或者全局内存的时候就比较慢，这种体系结构被称为Non-Uniform Memory Access(NUMA)。

以上是硬件层面上的NUMA，而作为软件层面的Linux，则对NUMA的概念进行了抽象。即便硬件上是一整块连续内存的UMA，Linux也可将其划分为若干的node。同样，即便硬件上是物理内存不连续的NUMA，Linux也可将其视作UMA。

所以，在Linux系统中，你可以基于一个UMA的平台测试NUMA上的应用特性。从另一个角度，UMA就是只有一个node的特殊NUMA，所以两者可以统一用NUMA模型表示。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%201.png)

在NUMA系统中，当Linux内核收到内存分配的请求时，它会优先从发出请求的CPU本地或邻近的内存node中寻找空闲内存，这种方式被称作local allocation，local allocation能让接下来的内存访问相对底层的物理资源是local的。

每个node由一个或多个zone组成（我们可能经常在各种对虚拟内存和物理内存的描述中迷失，但以后你见到zone，就知道指的是物理内存），每个zone又由若干page frames组成（一般page frame都是指物理页面）。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%202.png)

## 分段与分页

通过前面的文章我们已经知道了，程序在运行过程中使用的都是虚拟地址，那么操作系统到底是如果将虚拟地址转换为一个物理地址的呢？

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%203.png)

系统会将整个物理内存分为多个页框，每个页框大小一般是4K(硬件允许的扩展分页(PSE)情况下也可设置为4M，不过linux并不使用PSE，而可能使用PAE)，也就是如果我们有1GB的物理内存，系统就会将这个物理内存分为262144个页框。当我们提供一个线性地址时，系统就会通过分页机制将这个线性地址转换为对应于某个物理页中的某个内存地址。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%204.png)

以 32 位地址空间为例，分页大小为 4KB（最常用的分页大小），上述抽象例子中的 X 为 12，那么 VPN 长度就是 20bit，偏移量为 12bit。20bit 的 VPN 意味着操作系统需要 2^20 个地址转换映射，假设每个转换映射需要 4Byte 空间存储，那么所有映射关系需要 4MB 空间。就是说每个进程都需要 4MB 的空间来存储页表。如果操作系统运行 100 个进程，则需要 400MB 空间。可见页表所需要的空间是很大的，所以**页表都存储在物理内存中**。即 MMU 通将虚拟地址转换为物理地址，需要访问物理内存中对应的页表。当然页表占用物理内存大的问题还是需要解决的，这是分页相对于分段的一个劣势。

考虑到分页机制占用内存过多的问题，实际的分页机制是多级分页。以二级页表为例，如下图所示，MMU 通过页表基址寄存器配合虚拟地址中的 PGD index（Page Global Directory）找到一级页表，通过一级页表配合虚拟地址中的 PTE index（Page Table Entry）找到二级页表，通过二级页表配合虚拟地址中 Offset 找到物理地址。多级页表要做到节省内存，还需要配合缺页异常，进程往往只需将一级页表保持到内存中，二级页表在缺页异常时再分配。下图示例中，一级页表一共 4096 项，二级页表一共 512 项。因此进程页表可以只使用 4096 X 4Byte 空间即可。如果使用一级页表，则需要 2097152 X 4Byte 空间。因此**多级页表带来的最大好处就是降低了内存空间的占用**。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%205.png)

下图是linux的分页模型

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%206.png)

linux采用四级分页模型，这四种页表是：**页全局目录(PGD)、页上级目录(PUD)、页中间目录(PMD)、页表(PTE)**。这里的所有页全局目录、页上级目录、页中间目录、页表，它们的大小都是一个页。linux下各个硬件上并不一定都是使用四级目录的，当使用于没有启动物理地址扩展(PAE)的32位系统上时，只使用二级页表，linux会把页上级目录和页中间目录置空。而在启用了物理地址扩展的32位系统上时，linux使用的是三级页表，页上级目录被置空。而在64位系统上，linux根据硬件的情况会选择三级页表或者四级页表。这个整个由线性地址转换到物理地址的过程，是由CPU自动进行的。

每个进程都有它自己的页全局目录，当进程运行时，系统会将该进程的页全局目录基地址保存到cr3寄存器中；而当进程被换出时，会将这个cr3保存的页全局目录地址保存到进程描述符中。之后我们还会介绍一个cr2寄存器，用于缺页异常处理的。当进程运行时，它使用的是它自己的一套页表，当它通过系统调用或陷入内核态时，使用的是内核页表，实际上，对于所有的进程页表来说，它们的线性地址0xC0000000以上所涉及到的页表都是主内核页全局目录(保存在init_mm.pgd)，它们的内容等于主内核页全局目录的相应表项，这样就实现了所有进程的进程空间相互隔离，但是内核空间相互共享的情况。当某个进程修改了内核页表的一些映射情况后，系统只会相应的修改主内核页全局目录中的表项(只能修改高端内存中非连续内存区的映射)，当其他进程访问这些线性地址时，会出现缺页异常，然后修改该进程的页表项重新映射该地址。

因为说到每个进程都有它自己的页全局目录，如果有100个进程，内存中就要保存100个进程的整个页表集，看起来会耗费相当多的内存。实际上，只有进程使用到的情况下系统才会分配给进程一条路径，比如我们要求访问一个线性地址，但是这个地址可能对应的页上级目录、页中间目录、页表和页都不存在的，这时系统会产生一个缺页异常，在缺页异常处理中再给进程的这个线性地址分配页上级目录、页中间目录、页表和页所需的物理页框。

- **TLB**

**页表是存在内存里的，如果按上文所说的4几页表，那就是一次内存 IO 光是虚拟地址到物理地址的转换就要去内存查 4 次页表，再算上真正的内存访问，最坏情况下需要 5 次内存 IO 才能获取一个内存数据!!**

这种情况下，TLB应运而生。TLB 和 CPU 的 L1、L2、L3 的缓存思想一致，既然进行地址转换需要的内存 IO 次数多，且耗时。那么干脆就在 CPU 里把页表尽可能地 cache 起来不就行了么，所以就有了 TLB(Translation Lookaside Buffer)，专门用于改进虚拟地址到物理地址转换速度的缓存。其访问速度非常快，和寄存器相当，比 L1 访问还快。

## 内存分配函数

### 用户空间 *malloc*

malloc 函数使 C/C++ 中常用内存分配库函数，使用 malloc 时，需包含头文件 <stdlib.h>，函数原型如下:

```cpp
void* malloc(size_t size);
```

- 功能：分配长度为 size 的内存块，一般为系统堆上的可用内存上找到一块长度大于 size 的连续内存空间。如果分配成功，则返回指向分配内存的指针，否则返回空指针 NULL。
- 返回值：类型为 void *，表示未确定类型指针，它可以强制转换为任意其他类型的指针
- 当内存不再使用时，应用 free 函数将内存块释放。将之前 malloc 分配的空间还给操作系统，释放传入指针指向的那块内存区域。指针本身的数值没有变，释放后，指向的内容是垃圾内容，所以最好将这块内存的指针再指向 NULL，防止后面的程序误用。

而对于进程的堆，并不是直接建立在 Linux 的内核的内存分配策略上的，而是**建立在 glibc 的堆管理策略上**的（也就是 glibc 的动态内存分配策略上），**堆的管理是由 glibc 进行的**。所以我们调用 free 对 malloc 得到的内存进行释放的时候，并不是直接释放给操作系统，而是还给了 glibc 的堆管理实体，而 glibc 会在把实际的物理内存归还给系统的策略上做一些优化，以便优化用户任务的动态内存分配过程。

***malloc 的调用规律*（该过程可以通过系统调用接口 strace 命令跟踪)**

1. **即分配一块小型内存 (小于或等于 128kb)，malloc() 会调用 brk()调高断点 (brk 是将数据段(.data) 的最高地址指针_edata 往高地址推)，分配的内存在堆区域。**
2. **当分配一块大型内存 (大于 128kb),malloc() 会调用 mmap()分配一块内存（mmap 是在进程的虚拟地址空间中（一般是堆和栈中间）找一块空闲的空间。**

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%207.png)

- ***brk***

1，进程启动的时候，其（虚拟）内存空间的初始布局如图所示

2，进程调用 A=malloc(30K) 以后，，将_edata 指针往高地址推 30K，就完成虚拟内存分配，内存空间如图：

3，进程调用 free(C) 以后，如下图所示，C 对应的虚拟内存和物理内存都没有释放，因为只有一个 _edata 指针，如果往回推，那么 C 这块内存怎么办呢？当然，C 这块内存是可以重用的，如果这个时候再来一个 30K 的请求，那么 malloc 很可能就将 C 这块内存返回。

4，进程调用 free(A) 以后，如下图所示，C 和 A 连接起来变成一块 60K 的空闲内存。当最高地址空间的空闲内存超过 128K（可由 M_TRIM_THRESHOLD 选项调节）时，执行内存紧缩操作（trim）。在上一个步骤 free 的时候，发现最高地址空闲内存超过 128K，于是内存紧缩，如下图所示。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%208.png)

事实是：_edata+30K 只是完成虚拟地址的分配，A 这块内存现在还是没有物理页与之对应的，等到进程第一次读写 A 这块内存的时候，发生缺页中断，这个时候，内核才分配 A 这块内存对应的物理页。也就是说，如果用 malloc 分配了 A 这块内容，然后从来不访问它，那么，A 对应的物理页是不会被分配的。

同时 brk 分配的内存需要等到高地址内存释放以后才能释放（例如，在 C 释放之前，A 是不可能释放的，这就是内存碎片产生的原因），而 mmap 分配的内存可以单独释放。

### 内核空间

我们知道，用户空间有***malloc***内存分配函数，内核空间同样有类似的内存分配函数，只是种类多一些 **(kmalloc/kfree, vmalloc/vfree, kmem_cache_alloc/kmem_cache_free, get_free_page)** 我们来看一下这些内核空间内存分配函数的具体作用范围：

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%209.png)

- **内核直接映射空间 PAGE_OFFSET~VMALLOC_START： kmalloc** 和 **__get_free_page**() 分配的是这里的页面。二者是借助 slab 分配器，直接分配物理页再转换为逻辑地址（物理地址连续）。适合分配小段内存。此区域 包含了内核镜像、物理页框表 mem_map 等资源。
- **内核动态映射空间 VMALLOC_START~VMALLOC_END：**被 vmalloc 用到，可表示的空间大。
- **内核永久映射空间 PKMAP_BASE ~ FIXADDR_START：**kmap
- **内核临时映射空间 FIXADDR_START~FIXADDR_TOP：**kmap_atomic

几个内存申请函数的作用范围或许通过下图可以更好地表述出来，图中有很快就会在下文提到的 伙伴系统(Buddy System) 与 slab，也可以一窥slab与Buddy System之间的关系。__alloc_pages会完成最终的内存分配，它是伙伴系统的核心代码（但是在内核代码中，这种命名方式的函数都是需要小心调用的，一般都是给实现该功能的代码自己调用，不作为API提供出去的，因而它的包装器才是对外提供的API，也就是alloc_pages_node）Kmalloc与Vmalloc的分配都是基于 __alloc_pages/伙伴系统之上所封装的接口，对应了不同的分配方式。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2010.png)

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2011.png)

| 用户/内核 | API名称 | 物理连续 | 大小限制 | 单位 | 场景 |
| --- | --- | --- | --- | --- | --- |
| 用户空间 | malloc/calloc/realloc/free |  不保证 |  堆申请 | 字节 | calloc初始化为0；realloc改变内存大小。 |
|  | alloca |  |  栈申请 | 字节 | 向栈申请内存 |
|  | mmap/munmap |   |   |  | 将文件利用虚拟内存技术映射到内存中去。 |
|  | brk、sbrk |   |   |  | 虚拟内存到内存的映射。sbrk(0)返回program break地址，sbrk调整对的大小。 |
| 内核空间

 |  vmalloc/vfree | 虚拟连续物理不定 |  vmalloc区大小限制 | 页
VMALLOC区域 | 可能睡眠，不能从中断上下文中调用，或其他不允许阻塞情况下调用。VMALLOC区域vmalloc_start ~ vmalloc_end之间，vmalloc比kmalloc慢，适用于分配大内存 |
| slab | kmalloc/kcalloc/krealloc/kfree | 物理连续 | 64B-4MB(随slab而变) | 2^order字节Normal区域 | 大小有限，不如vmalloc/malloc大。最大/小值由KMALLOC_MIN_SIZE / KMALLOC_SHIFT_MAX，对应64B/4MB。从/proc/slabinfo中的kmalloc-xxxx中分配，建立在kmem_cache_create基础之上。 |
| slab | kmem_cache_create | 物理连续 | 64B-4MB | 字节大小，需对齐Normal区域 | 便于固定大小数据的频繁分配和释放，分配时从缓存池中获取地址，释放时也不一定真正释放内存。通过slab进行管理。 |
| 伙伴系统 | __get_free_page/__get_free_pages | 物理连续 | 4MB(1024页) | 页Normal区域 |  __get_free_pages基于alloc_pages，但是限定不能使用HIGHMEM。 |
| 伙伴系统 |  alloc_page/alloc_pages/free_pages | 物理连续 | 4MB  | 页Normal/Vmalloc都可  |  CONFIG_FORCE_MAX_ZONEORDER定义了最大页面数2^11，一次能分配到的最大页面数是1024。 |

### _*_get_free_page*

***__get_free_page*** 系列函数申请的内存位于物理内存映射区域（什么是物理映射区？[虚拟内存(内核空间&用户空间)](%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98(%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4&%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4)%20919e35135f674d998286e9d031aa158a.md)） ，在物理上是连续的，注意，函数返回的是虚拟地址，其与物理地址有一个固定的偏移，存在比较简单的转换关系，*virt_to_phys()* 函数做的就是这件事。

以 **__get_free_pages** 为例看看其函数间调用关系(**仅包含了调用关系**)：

```cpp
unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)
{
		page = __alloc_pages会完成最终的内存分配，它是伙伴系统的核心代码（但是在内核代码中，这种命名方式的函数都是需要小心调用的，一般都是给实现该功能的代码自己调用，不作为API提供出去的，因而它的包装器才是对外提供的API，也就是alloc_pages_node）(gfp_mask, order);
}
#define alloc_pages(gfp_mask, order) \ 
				alloc_pages_node(numa_node_id(), gfp_mask, order)

static inline struct page *alloc_pages_node(int nid, gfp_t gfp_mask,unsigned int order)
{
		return __alloc_pages_node(nid, gfp_mask, order);
}
 
static inline struct page * __alloc_pages_node(int nid, gfp_t gfp_mask, unsigned int order)
{
		return __alloc_pages(gfp_mask, order, node_zonelist(nid, gfp_mask));
}
```

最终 ***__get_free_page*** 会调用 ***__alloc_pages*** 函数分配页面。***__alloc_pages*** 是伙伴系统所提供的所有页面分配函数的核心函数，最终都会调用到这个函数，它会返回一个 *struct page* 结构。

### *kmalloc*

与 *_get_free_page* 函数一样，*kmalloc* 函数申请的内存也处于**物理内存映射区域**，在物理上是连续的。*Kmalloc* 函数是 slab 分配器提供的分配内存的接口，slab 是什么？slab 是为了避免内部碎片使得一个页面内包含的众多小块内存可独立被分配使用，是为分配小内存提供的一种高效机制。追踪 **kmalloc** 函数，可以发现，它最终还是调用前面提到的***__alloc_pages()*** 函数。既然 ***kmalloc*** 基于 slab 实现，而 slab 分配机制又不是独立的，本身也是在以页面为单位分配的基础上来划分更细粒度的内存供调用者使用。就是说系统先用页分配器分配以页为最小单位的连续物理地 址，然后 *kmalloc* 再在这上面根据调用者的需要进行切分。从本质上讲，kmalloc 和 get_free_page 最终调用实现是相同的，只不过在调用最终函数时所传的 flag 不同而已。

既然 slab 是为了解决内部碎片的问题，那想必也有一个解决外部碎片的机制 (注：外部分片是指系统虽有足够的内存，但却是分散的碎片，无法满足对大块“连续内存” 的需求)。伙伴关系系统就是这么一个机制。伙伴关系系统提供 *vmalloc* 来分配非连续内存, 其分配的地址限于上述说的 *vmalloc_start~vmalloc_end* 之间。这些虚拟地址与物理内存没有简单的位移关系，必须通过内核页表才可转换为物理地址或物理页。它们有可能尚未被映射，在发生缺页时才真正分配物理页面。

### *kmem_cache_alloc*

***kmem_cache_alloc*** 也是基于 slab 分配器的一种内存分配方式，适用于反复分配同一大小内存块的场合。首先用 ***kmem_cache_create*** 创建一个高速缓存区域，然后用 ***kmem_cache_alloc*** 从该高速缓存区域获取新的内存块。***kmem_cache_alloc*** 分配固定大小的内存块。*kmalloc* 则是在 *kmem_cache_create* 的基础实现的，其分配动态大小的内存块，查看源码可以发现 *kmalloc* 函数中会有一段代码块转向调用 *kmem_cache_alloc*

### *vmalloc*

内核总是尝试使用物理上连续的内存区域，但是在分配内存时，可能无法找到大片的物理上连续的内存区域，这时候就需要使用不连续的内存，内核分配了其虚拟地址空间的一部分（vmalloc区）用于管理不连续内存页的分配。

每个vmalloc分配的子区域都自包含的，在内核的虚拟地址空间中vmalloc子区域之间都通过一个内存页隔离开来，这个间隔用来防止不正确的访问,这种page被称作**guard page**。你看，又是8MB的空洞间隔，又是那么多的guard page，多浪费空间啊……其实没关系的啦，因为这里都是虚拟地址空间，并没有多占用实际的物理内存。guard page也并不是强制的，可通过VM_NO_GUARD宏选择。

vmalloc用来分配在虚拟地址空间连续，但是在物理地址空间不一定连续的内存区域。它只需要一个以字节为单位的长度参数。为了节省宝贵的较低端的内存区域，vmalloc会使用高端内存进行分配。

内核使用struct vm_struct来管理vmalloc分配的每个子区域，其定义如下：

```cpp
struct vm_struct {
	struct vm_struct	*next;
	void			*addr;
	unsigned long		size;
	unsigned long		flags;
	struct page		**pages;
	unsigned int		nr_pages;
	phys_addr_t		phys_addr;
	const void		*caller;
};
```

所有的vmalloc子区域都被连接保存在vmlist中，该链表按照addr排序，顺序是从小到大。当创建一个新的子区域时需要，需要找到一个合适的位置。查找合适的位置采用的是首次适用算法，即从vmalloc区域找到第一个可以满足需求的区域，查找这样的区域是通过函数__get_vm_area_node完成的。其分配过程以下几步：

1. 调用 __get_vm_area_node 找到合适的区域
2. 调用 __vmalloc_area_node 分配物理内存页
3. 调用 map_vm_area 将物理内存页映射到内核的读你地址空间
4. 将新的子区域插入 vmlist 链表

那vm_struct这个控制结构本身又是存在什么地方的呢？它不是和它要管理的vmalloc区域一起放在vmalloc area的（没有和群众打成一片啊）**，而是放在normal area的（有自己单独的办公室），也就是说，vm_struct结构体占用的内存是通过kmalloc()分配的。**

- **vamalloc的问题**
    
    1、由于kmalloc()基于的是直接映射，其虚拟地址和物理地址之间是一个固定的偏移，因此可以利用既有的内核页表，而不需要为新的地址增加新的page table entries，因此其分配速度也比vmalloc()更快。
    
    2、因为物理地址不连续，通过vmalloc()获得的每个page需要单独映射，而TLB资源很有限，因此这将比直接映射造成更严重的TLB thrashing问题。
    
- **新版内核的vmalloc**
    
    当vmalloc区域的数量变多之后，遍历vmlist链表查找会面临进程地址空间中vm_area_struct曾经也遇到的问题，就是效率太低。vm_area_struct采用了加入红黑树来共同管理的方法，从内核2.6的某个版本（还不知道具体是哪个版本）开始，vmalloc区域也开始使用**红黑树**（每个节点用**vmap_area**结构体表示），而且查找的时候也首先从一个缓存（free_vmap_cache，对应进程地址空间中的mmap_cache）中找。反正，两者在管理机制上是越来越像了。
    

### kmap

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2012.png)

相较于**NORMAL**_**ZONE**（对应32位的x86是物理地址0~896MB）的线性映射（因为是1:1的对应关系，虚拟地址不会复用，所以算是permenant map），vmalloc region和PKmap region都算是temporary map。同样是**临时映射**，但还是可以区分一下。vmalloc()主要用于分配物理内存，并建立和虚拟地址的映射，如果已经分配好了物理内存（比如alloc_page()后），只是想建立映射，则可以使用vmap()。vmap()算是vmalloc()的一个组成部分。**vmap()用于相对长时间的映射，可同时映射多个pages，kmap()和kmap_atomic()则用于相对短时间的映射，只能映射单个page**。至于为什么叫做“永久”映射区我也不知道。。

KMAP 内存管理器用于分配和释放零时映射虚拟内存。Linux 从内核虚拟空间划分 一段大小为 2MB 的虚拟内存，起始地址 PKMAP_BASE。在有的体系中，物理内存 远远大于内核的虚拟地址空间，Linux 需要零时将指定的物理内存映射到虚拟地址 上，以便完成指定的任务，当任务完成之后就解除物理内存和虚拟内存之间的关系。 那么 VMALLOC 也可以实现这样的功能，当为什么不使用 VMALLOC 分配器分配呢? 可能的原因有很多，其中之一是 **VMALLOC 分配器分配的虚拟地址和物理地址之间 映射时间一般很长，毕竟短时间的映射页表开销也不小**; 另外一个原因可能是 **VMALLOC 分配器分配的虚拟地址是连续了，为了最大限度保持虚拟内存的连续， 所以不建议使用 VMALLOC 做短时间的零时映射**. Linux 内核于是推出了 KMAP 内存 管理器，用于短时间的虚拟内存到物理内存映射，满足一些任务的需要.

### kmap_atomic

`**kmap`函数不能用于中断处理程序, 因为它可能进入睡眠状态. 如果`pkmap`数组中没有空闲位置, 该函数会进入睡眠状态, 直至情形有所改善。**在某些情况下，比如interrupt context或者是process context但持有spin lock时（其实都属于atomic上下文），都是不能睡眠等待的，这时要建立映射，就得靠kmap_atomic()了。

因此内核提供了一个备选的映射函数, 其执行是原子的, 逻辑上称为`kmap_atomic`. kmap_atomic 用于高端内存映射，用于紧急的，短时间的映射，它没有使用任何锁，完全靠一个数学公式来避免混乱，它空间有限且虚拟地址固定，这意味着它映射的内存不能长期被占用而不被 unmap，kmap_atomic 在效率上要比 kmap 提升不少，然而它和 kmap 却不是用于同一场合的。

该函数的一个主要优点是它比普通的`kmap`快速. 但它不能用于可能进入睡眠的代码. 因此, 它对于很快就需要一个临时页的简短代码，是非常理想的.

## 页框分配器

ZONE_NORMAL 和 ZONE_DMA 的地址直接映射到了内核地址空间，但是也不代表内核的代码可以随心所欲的通过线性地址直接访问物理地址。内核通过一个 **管理区页框分配器** 管理着物理内存上所有的页框，在管理区分配器里的核心系统就是伙伴系统和每 CPU 页框高速缓存 (不是硬件上的高速缓存，只是名称一样)。在 linux 系统中，管理区页框分配器管理着所有物理内存，**无论你是内核还是进程，需要将一些内存占为己有时，都需要请求管理区页框分配器**，这时才会分配给你应该获得的物理内存页框。当你所拥有的页框不再使用时，你必须释放这些页框，让这些页框回到管理区页框分配器当中。特别的，对于高端内存，即使从管理区页框分配器中获得了相应的页框，我们还需要进行映射才能够使用。

有时候目标管理区不一定有足够的页框去满足分配，这时候系统会从另外两个管理区中获取要求的页框，但这是按照一定规则去执行的，如下：

- 如果要求从 DMA 区中获取，就只能从 ZONE_DMA 区中获取。
- 如果没有规定从哪个区获取，就按照顺序从 ZONE_NORMAL -> ZONE_DMA 获取。
- 如果规定从 HIGHMEM 区获取，就按照顺序从 ZONE_HIGHMEM -> ZONE_NORMAL -> ZONE_DMA 获取。

注意系统是不允许在一次分配中从不同的两个管理区获取页框的，并且当请求多个页框时，从伙伴系统中分配给目标的页框是连续的，并且请求的页数必须是 2 的次方个数。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2013.png)

管理区分配器主要做的事情就是将页框通过伙伴系统或者每 CPU 页框高速缓存分配出去，这里涉及到三个结构，页描述符，伙伴系统，每 CPU 高速缓存。

我们先说说页描述符，**页描述符实际上并不专属于描述页框，它还用于描述一个 SLAB 分配器和 SLUB 分配器。**

linux 为了防止内存中产生过多的碎片，一般把页的类型分为三种：

- **不可移动页：**在内存中有固定位置，不能移动到其他地方。内核中使用的页大部分是属于这种类型。
- **可回收页：**不能直接移动，但可以删除，页中的内容可以从某些源中重新生成。例如，页内容是映射到文件数据的页就属于这种类型。对于这种类型，在内存短缺 (分配失败) 时，会发起内存回收，将这类型页进行回写释放。
- **可移动页：**可随意移动，用户空间的进程使用的没有映射具体磁盘文件的页就属于这种类型 (比如堆、栈、shmem 共享内存、匿名 mmap 共享内存)，它们是通过进程页表映射的，把这些页复制到新位置时，只要更新进程页表就可以了。一般这些页是从高端内存管理区获取。

## 外部碎片与内部碎片

- **外部碎片**

外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。

- **内部碎片**

内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间；内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。

## Buddy System 伙伴系统

**伙伴算法（buddy算法）**，是为了核心内存管理能够快速响应请求，尽可能地在提高内存利用率的同时**减少外部内存碎片**的一种算法。

首先我们先要了解什么是“伙伴”？我们将伙伴关系的定义为：由一个母实体分成的两个各方面属性一致的两个子实体，这两个子实体就处于伙伴关系。在操作系统分配内存的过程中，一个内存块经常被分成两个大小相等的内存块，这两个大小相等的内存块就处于伙伴关系。它满足3个条件：

1）两个块大小相同；

2）两个块地址连续；

3）两个块必须是同一个大块中分离出来的；

### Buddy**算法原理**

我们知道内存是以“页”为单位进行分配的。我们前面提到了外部内存碎片与内部内存随便，Buddy算法便是外部内存碎片的一种解决方案。在内存中，为了便于页面的维护，我们将多个页面组成内存块。**同时我们规定每个内存块都有2的方幂个页，方幂的指数被称为阶**。在操作内存时，经常将这些内存块分成大小相等的两个块，分成的两个内存块相互之间被称为伙伴块，采用一位二进制数来表示它们的伙伴关系。当这个位为1，表示其中一块在使用；当这个位为0，表示两个页面块都空闲或者都在使用。系统根据该位为0或位为1来决定是否使用或者分配该页面块。系统每次分配和回收伙伴块时都要对它们的伙伴位跟1进行异或运算。所谓异或是指刚开始时，两个伙伴块都空闲，它们的伙伴位为0，如果其中一块被使用，异或后得1；如果另一块也被使用，异或后得0；如果前面一块回收了异或后得1；如果另一块也回收了异或后得0。

### Buddy算法的实现

如前面提到的实现方式，我们在内核在每个 zone 区管理着可用的页面，按 2 的幂级(order)大小排成链表队列，存放在 **free_area** 数组。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2014.png)

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2015.png)

- **控制位(伙伴位图)
具体 buddy 管理基于位图，**假设我们的系统内存只有 ***16 个页面 RAM***。因为 RAM 只有 16 个页面，我们只需用四个级别（orders）的伙伴位图（***因为最大连续内存大小为 16 个页面***），如下图所示。举个例子，order[0]中第一个bit代表0页与1页，order[1]中第一个bit代表 长度为2^1 的第1个块(1,2)与第2个块(3,4)的关系。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2016.png)

- **分配过程**

假如系统需要4(2*2)个页面大小的内存块，该算法就到free_area[2]中查找，如果链表中有空闲块，就直接从中摘下并分配出去。如果没有，算法将顺着数组向上查找free_area[3],如果free_area[3]中有空闲块，则将其从链表中摘下，分成等大小的两部分，前四个页面作为一个块插入free_area[2]，后4个页面分配出去，free_area[3]中也没有，就再向上查找，如果free_area[4]中有，就将这16(2*2*2*2)个页面等分成两份，前一半挂如free_area[3]的链表头部，后一半的8个页等分成两等分，前一半挂free_area[2]的链表中，后一半分配出去。假如free_area[4]也没有，则重复上面的过程，知道到达free_area数组的最后，如果还没有则放弃分配。同时我们在分配过程中需要维护Buddy的伙伴位图，如我们需要一个页，在  **free_area[1]** 链表中取下一个2^1个页的块时。我们分配了其中一个块，同时需要在 **order[0]** 对应的位置上异或一次。

- **合并过程**

内存的释放是分配的逆过程，也可以看作是伙伴的合并过程。当释放一个块时，先在其对应的链表中考查是否有伙伴存在，如果没有伙伴块，就直接把要释放的块挂入链表头；如果有，则从链表中摘下伙伴，合并成一个大块，然后继续考察合并后的块在更大一级链表中是否有伙伴存在，直到不能合并或者已经合并到了最大的块(2*2*2*2*2*2*2*2*2个页面)。

整个过程中，位图扮演了重要的角色，位图的某一位对应两个互为伙伴的块，为1表示其中一块已经分配出去了，为0表示两块都空闲或是两块都忙碌。伙伴中无论是分配还是释放都只是相对的位图进行异或操作。分配内存时对位图的是为释放过程服务，释放过程根据位图判断伙伴是否存在，如果对相应位的异或操作得1，则没有伙伴可以合并，如果异或操作得0，就进行合并，并且继续按这种方式合并伙伴，直到不能合并为止。

### Buddy算法缺点

1）尽管伙伴内存算法在内存碎片问题上已经做的相当出色，但是该算法中，一个很小的块往往会阻碍一个大块的合并，一个系统中，对内存块的分配，大小是随机的**，一片内存中仅一个小的内存块没有释放，旁边两个大的就不能合并**。

2）算法中有一定的浪费现象，伙伴算法是按 2 的幂次方大小进行分配内存块，当然这样做是有原因的，即为了避免把大的内存块拆的太碎，更重要的是使分配和释放过程迅速。但是他也带来了不利的一面，如果所需内存大小不是 2 的幂次方，就会有部分页面浪费。有时还很严重。比如原来是 1024 个块，申请了 16 个块，再申请 600 个块就申请不到了，因为已经被分割了。

3）另外拆分和合并涉及到 较多的链表和位图操作，开销还是比较大的。

## 预防内存碎片

物理内存的碎片化一直是 Linux 操作系统的弱点之一，尽管已经有人提出了很多解决方法，但是没有哪个方法能够彻底的解决，memory buddy 分配就是解决方法之一。 我们知道磁盘文件也有碎片化问题，但是磁盘文件的碎片化只会减慢系统的读写速度，并不会导致功能性错误，而且我们还可以在不影响磁盘功能的前提的下，进行磁盘碎片整理。而物理内存碎片则截然不同，物理内存和操作系统结合的太过于紧密，以至于我们很难在运行时，进行物理内存的搬移。 因此解决的方向主要放在预防碎片上。在 2.6.24 内核开发期间，防止碎片的内核功能加入了主线内核。在了解反碎片的基本原理前，先对内存页面做个归类：

- **不可移动页面 unmoveable**：在内存中位置必须固定，无法移动到其他地方，核心内核分配的大部分页面都属于这一类。
- **可回收页面 reclaimable**：不能直接移动，但是可以回收，因为还可以从某些源重建页面，比如映射文件的数据属于这种类别，kswapd 会按照一定的规则，周期性的回收这类页面。
- **可移动页面 movable**：可以随意的移动。属于用户空间应用程序的页属于此类页面，它们是通过页表映射的，因此我们只需要更新页表项，并把数据复制到新位置就可以了，当然要注意，一个页面可能被多个进程共享，对应着多个页表项。

防止碎片的方法就是把这三类 page 放在不同的链表上，避免不同类型页面相互干扰。考虑这样的情形，一个不可移动的页面位于可移动页面中间，那么我们移动或者回收这些页面后，这个不可移动的页面阻碍着我们获得更大的连续物理空闲空间。

## *slab* 分配器

在Linux中，伙伴分配器（buddy allocator）是以页为单位管理和分配内存。但在内核中的需求却以字节为单位（在内核中面临频繁的结构体内存分配问题）。假如我们需要动态申请一个内核结构体（占 20 字节），若仍然分配一页内存，这将严重浪费内存，造成内存内部碎片问题。那么该如何分配呢？slab 分配器专为小内存分配而生，由Sun公司的一个雇员`Jeff Bonwick`在`Solaris 2.4`中设计并实现。slab分配器分配内存以字节为单位，基于伙伴分配器的大内存进一步细分成小内存分配。换句话说，**slab 分配器仍然从 Buddy 分配器中申请内存，之后自己对申请来的内存细分管理**。

实际上slab分配器与常见的对象内存池是很相似的，**处理策略核心都是使用对象来管理内核内存空间**。什么叫对象？这里的对象就是指具体相同的数据结构和大小的某个内存单元。内核中有需要需要频繁申请与释放的结构，比方上面所说的mm_struct结构体。我们知道，内核每创建一个进程时就需要给其分配mm_struct，这样一来内核中需要维护这个结构体的数目是相当多的，如果全部使用buddy分配器来分配，那么将会产生大量的碎片。而且，这种结构体在内核中分配和释放的频率是很高的，每分配一次又需要对它初始化，用过以后又需要释放，对系统的性能影响也很大。

举例来说, 为管理与进程关联的文件系统数据, 内核必须经常生成`struct fs_struct`的新实例. 此类型实例占据的内存块同样需要经常回收(在进程结束时). 换句话说, 内核趋向于非常有规律地分配并释放大小为`sizeof(fs_struct)`的内存块. slab分配器将释放的内存块保存在一个内部列表中. 并不马上返回给伙伴系统. 在请求为该类对象分配一个新实例时, 会使用最近释放的内存块。S这有两个优点. 首先, 由于内核不必使用伙伴系统算法, 处理时间会变短. 其次, 由于该内存块仍然是”新”的，因此其仍然驻留在CPU硬件缓存的概率较高.

### *slab* 实现

在具体实现层面，slab为需要缓存的对象创建一个cache (从Buddy分配器中获取，使用结构体`kmem_cache` 描述)。每个cache所占的内存区又被划分多个slab，每个 slab是由一个或多个连续的页框组成。每个页框中包含若干个对象，既有已经分配的对象，也包含空闲的对象。下图是slab分配器的大致思想，实际上与堆内存中我们使用内存池管理对象非常相似，但是内核空间我们需要考虑与Buddy分配器以及内存页的管理，将所有的这些因素结合的产物便是我们看到的slab。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2017.png)

具体到实现的层面，我们将Buddy分配器分配的一个或多个连续的内存页使用 `kmem_cache` 描述。我们可以看一下其描述：

```cpp
struct kmem_cache {
/* 高速缓存永久属性的标识，如果SLAB描述符放在外部(不放在SLAB中)，则CFLAGS_OFF_SLAB置1 */
    slab_flags_t flags; 
/* 每个SLAB中对象的个数(在同一个高速缓存中slab中对象个数相同) */
    unsigned int num;
/* 每个 slab 所使用的页框数量 order */
    unsigned int gfporder; 
/* 分配页框时传递给伙伴系统的一组标识 */
    gfp_t allocflags; 
/* SLAB使用的颜色个数 */
    size_t colour;   
/* SLAB中基本对齐偏移，当新SLAB着色时，偏移量的值需要乘上这个基本对齐偏移量，理解就是1个偏移量等于多少个B大小的值 */
    unsigned int colour_off; 
/* 空闲对象链表放在外部时使用，其指向的SLAB高速缓存来存储空闲对象链表 */
    struct kmem_cache *freelist_cache;
/* 空闲对象链表的大小 */
    unsigned int freelist_size;

/* 存放高速缓存名字 */
    const char *name;
/* 高速缓存描述符双向链表指针 */
    struct list_head list;
    int refcount;
/* 高速缓存中对象的大小 */
    int object_size;
    int align;

/* 结点链表，此高速缓存可能在不同NUMA的结点都有SLAB链表 */
    struct kmem_cache_node *node[MAX_NUMNODES];
};
```

**从结构中可以看出，在这个 kmem_cache 中所有对象的大小是相同的 (object_size)，并且此 kmem_cache 中所有 SLAB 的大小也是相同的 (gfporder、num)。**

在这个结构中，最重要的可能就属 `struct kmem_cache_node * node[Max_NUMNODES]` 这个指针数组了，指向的 `struct kmem_cache_node` 中保存着 slab 链表，在 NUMA 架构中每个 node 对应数组中的一个元素，因为每个 SLAB 高速缓存都有可能在不同结点维护有自己的 SLAB 用于这个结点的分配。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2018.png)

我们看看 `struct kmem_cache_node` :

```cpp
/* SLAB链表结构 */
struct kmem_cache_node {
    /* 锁 */
    spinlock_t list_lock;

/* SLAB用 */
    /* 只使用了部分对象的SLAB描述符的双向循环链表 */
    struct list_head slabs_partial;    /* partial list first, better asm code */
    /* 不包含空闲对象的SLAB描述符的双向循环链表 */
    struct list_head slabs_full;
    /* 只包含空闲对象的SLAB描述符的双向循环链表 */
    struct list_head slabs_free;
    /* 高速缓存中空闲对象个数(包括slabs_partial链表中和slabs_free链表中所有的空闲对象) */
    unsigned long free_objects;
    /* 高速缓存中空闲对象的上限 */
    unsigned int free_limit;
    /* 下一个被分配的SLAB使用的颜色 */
    unsigned int colour_next;    /* Per-node cache coloring */
    /* 指向这个结点上所有CPU共享的一个本地高速缓存 */
    struct array_cache *shared;    /* shared per node */
    struct alien_cache **alien;    /* on other nodes */
    /* 两次缓存收缩时的间隔，降低次数，提高性能 */
    unsigned long next_reap;    
    /* 0:收缩  1:获取一个对象 */
    int free_touched;        /* updated without locking */
};
```

在这个结构中，最重要的就是 slabs_partial、slabs_full、slabs_free 这三个链表头。

- **slabs_partial：**维护部分对象被使用了的 SLAB 链表，保存的是 SLAB 描述符。
- **slabs_full：**维护所有对象都被使用了的 SLAB 链表，保存的是 SLAB 描述符。
- **slabs_free：**维护所有对象都没被使用的 SLAB 链表，保存的是 SLAB 描述符。

SLAB 就是一组连续的页框，**它的描述符结合在页描述符中**，也就是页描述符描述 SLAB 的时候，就是 SLAB 描述符。这三个链表保存的是这组页框的首页框的 SLAB 描述符。链表的组织形式与伙伴系统的组织页框的形式一样。

刚开始创建 kmem_cache 完成后，这三个链表都为空，只有在申请对象时发现没有可用的 slab 时才会创建一个新的 SLAB，并加入到这三个链表中的一个中。也就是说 kmem_cache 中的 SLAB 数量是动态变化的，当 SLAB 数量太多时，kmem_cache 会将一些 SLAB 释放回页框分配器中。

```cpp
struct page {
    /* First double word block */
    /* 用于页描述符，一组标志(如PG_locked、PG_error)，也对页框所在的管理区和node进行编号 */
    unsigned long flags; /
    union {
        /* 用于页描述符，当页被插入页高速缓存中时使用，或者当页属于匿名区时使用 */
        struct address_space *mapping; 
        /* 用于SLAB描述符，指向第一个对象的地址 */
        void *s_mem;            /* slab first object */
    };
    /* Second double word */
    struct {
        union {
            /* 作为不同的含义被几种内核成分使用。例如，它在页磁盘映像或匿名区中标识存放在页框中的数据的位置，或者它存放一个换出页标识符 */
            pgoff_t index;        /* Our offset within mapping. */
            /* 用于SLAB描述符，指向空闲对象链表 */
            void *freelist;    
            /* 当管理区页框分配器压力过大时，设置这个标志就确保这个页框专门用于释放其他页框时使用 */
            bool pfmemalloc; 
        };

    /* Third double word block */
    union {
        /* 包含到页的最近最少使用(LRU)双向链表的指针，用于插入伙伴系统的空闲链表中，只有块中头页框要被插入。也用于SLAB，加入到kmem_cache中的SLAB链表中 */
        struct list_head lru;    
        /* SLAB使用 */
        struct {        /* slub per cpu partial pages */
            struct page *next;    /* Next partial slab */
            int pages;    /* Nr of partial slabs left */
            int pobjects;    /* Approximate # of objects */
        };

        /* SLAB使用 */
        struct slab *slab_page; /* slab fields */
    };

    /* Remainder is not double word aligned */
    union {
        /* 可用于正在使用页的内核成分(例如: 在缓冲页的情况下它是一个缓冲器头指针，如果页是空闲的，则该字段由伙伴系统使用，在给伙伴系统使用时，表明的是块的2的次方数，只有块的第一个页框会使用) */
        unsigned long private;        
        /* SLAB描述符使用，指向SLAB的高速缓存 */
        struct kmem_cache *slab_cache;    /* SL[AU]B: Pointer to slab */
        struct page *first_page;    /* Compound tail pages */
    };

}
```

- `void *s_mem`: 指向该页框中第一个object 的地址 。
- `struct kmem_cache *slab_cache`: 获得结构体`kmem_cache_node`后，用其追踪所有 page 的链表。
- `void *freelist`: 用于指向页框中空闲对象链表。空闲对象链表包含页框中每个空闲对象的索引。

空闲对象链表是一个由数组制成的简单链表，它保存的地方有两种情况：

- **保存在外部，会从 SLAB 中分配一个对象用于保存新的 SLAB 的空闲对象链表。**
- **保存在内部，保存在这个 SLAB 所代表的连续页框的头部。**

不过一般没有什么其他情况空闲对象链表都是保存在内部居多，这里我们只讨论将空闲对象链表保存在内部的情况，这种情况下，这个 SLAB 所代表的连续页框的头部首先放的就是空闲对象链表，后面接着放的是对象描述符数组 (1,2 个字节大小)，之后紧接着就是对象所代表的内存了，如下图：

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2019.png)

我们看看 freelist 数组是怎么形成一个链表的，之前我们也说了分配时会优先分配最近释放的对象，整个 freelist 跟 struct page 中的 active 有很大联系，可以说 active 决定了下个分配的对象是谁，在 freelist 数组制作成的链表中，active 作为下标，保存目标空闲对象的对象号，在活动过程中，动态修改这个数组中的值。我们用一幅图可以很清楚看出 freelist 是如何实现：

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2020.png)

SLAB 中的连续页框个数与 kmem_cache 结构中的 gfporder 有关，而这个 gfporder 在初始化时通过对象数量、大小、freelist 大小、对象描述符数组大小和着色区计算出来的。而对于对象的大小，也并不是你创建时打算使用的大小，比如，我打算创建一个 kmem_cache 的对象大小是 10 字节，而在创建过程中，系统会帮你优化和初始化这些对象，包括将你的对象保存地址放在内存对其标志，在对象的两边放入一些填充区域 (RED_ZONE) 进行防止越界等工作。

### slab 着色问题

在研究slab着色问题之前我们需要先了解：[CPU Cache](CPU%20Cache%20dc3c67120bfb4c389d3df957be390e3c.md) 

着色问题看名字很难理解，其实又很好理解，我们知道内存需要处理时要先放入 CPU 硬件高速缓存中，而 CPU 硬件高速缓存与内存的映射方式有多种。在同一个 kmem_cache 中所有 SLAB 都是相同大小，都是相同连续长度的页框组成，这样的话在不同 SLAB 中相同对象号对于页框的首地址的偏移量也相同，这样有很可能导致不同 SLAB 中相同对象号的对象放入 CPU 硬件高速缓存时会处于同一行，当我们交替操作这两个对象时，CPU 的 cache 就会交替换入换出，效率就非常差。

具体来说，由于cache一般不会采取全相联的映射形式，一般采用的是直接映射或是组相联映射(主要是组相联)。举个例子，一般来说L1是32K的大小，分为64个组，一个cache line为64bytes(这样的设计很巧妙，因为 64组*64bytes 正好等于4K，即一个页大小) 分为8路 ( 8way*64组*64bytes = 32K )。所以4K内存页内如果偏移为0那么都会映射到cache的第一组里面(一组里面有8路)。这样的话如果同一时间有大量的slab从slab头开始调用就会产生大量的cache line 的替换。

实际上个人看来，硬件的进步让很多原来严重的问题没那么严重了。就拿slab着色问题作为例子，本来采用直接映射的方式，相当于只有1路的情况。此时如果产生同时调slab头的问题就会严重很多，在同一时间将会退化为仅有一个核在调用。

SLAB 着色就是在同一个 kmem_cache 中对不同的 SLAB 添加一个偏移量，就让相同对象号的对象不会对齐，将第二块读取的数据前加一个偏移，让它移到第 1 块缓存行上面，两块数据分别可以在缓存行的 0 和 1 行上面进行读取，那么我们读取数据的时候就不会造成不必要的数据交换。

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2021.png)

着色空间就是前端的空闲区域，这个区有大小都是在分配新的 SLAB 时计算好的，计算方法很简单，node 结点对应的 kmem_cache_node 中的 colour_next 乘上 kmem_cache 中的 colour_off 就得到了偏移量，然后 colour_next++，当 colour_next 等于 kmem_cache 中的 colour 时，colour_next 回归到 0。

### *slab*着色 与 *false sharing*问题

**false sharing问题：**

![Untitled](Linux%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6%209d21f14218864a9a9fbe85ca969926c4/Untitled%2022.png)

上图中`thread0`位于`core0`，而`thread1`位于`core1`，二者均想更新彼此独立的两个变量，但是由于两个变量位于同一个`cache line`中，此时可知的是两个`cache line`的状态应该都是`Shared`，而对于`cache line`的操作`core`间必须争夺主导权`（ownership）`，如果`core0`抢到了，`thread0`因此去更新`cache line`，会导致`core1`中的`cache line`状态变为`Invalid`，随后`thread1`去更新时必须通知`core0`将`cache line`刷回主存，然后它再从主从中`load`该`cache line`进高速缓存之后再进行修改，但令人抓狂的是，该修改又会使得`core0`的`cache line`失效，重复上演历史，从而高速缓存并未起到应有的作用，反而影响了性能。

这个slab 着色的问题和 false sharing的问题比较像，也比较容易弄混。slab着色的核心是不同数据映射到同一个cache line 导致cache line频繁替换。而false sharing核心问题在与统一数据被多核心同时更改，导致MESI协议频繁在cache之间同步数据。